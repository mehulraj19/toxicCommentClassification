{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35975826",
   "metadata": {},
   "source": [
    "# SIN Project\n",
    "\n",
    "Models implemented:\n",
    "<ul>\n",
    "    <li>MultinomialNB</li>\n",
    "    <li>RandomForestClassifier</li>\n",
    "    <li>LogisticRegression</li>\n",
    "    <li>SGDClassifier</li>\n",
    "    <li>Perceptron</li>\n",
    "    <li>MLPClassifier</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4d88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695d9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading CSV\n",
    "train = pd.read_csv('train.csv').fillna('unknown')\n",
    "test = pd.read_csv('test.csv').fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9950f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4d4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "y = train[class_names]\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0553570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making tf-idf vectors\n",
    "word_vectorizer = TfidfVectorizer(ngram_range =(1,3),\n",
    "                             min_df=3, max_df=0.9,\n",
    "                             strip_accents='unicode',\n",
    "                             stop_words = 'english',\n",
    "                             analyzer = 'word',\n",
    "                             use_idf=1,\n",
    "                             smooth_idf=1,\n",
    "                             sublinear_tf=1 )\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(ngram_range =(1,4),\n",
    "                                 min_df=3, max_df=0.9,\n",
    "                                 strip_accents='unicode',\n",
    "                                 analyzer = 'char',\n",
    "                                 stop_words = 'english',\n",
    "                                 use_idf=1,\n",
    "                                 smooth_idf=1,\n",
    "                                 sublinear_tf=1,\n",
    "                                 max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e281d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:502: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = make_union(word_vectorizer, char_vectorizer)\n",
    "vectorizer.fit(all_text)\n",
    "\n",
    "train_matrix =vectorizer.transform(train['comment_text'])\n",
    "test_matrix = vectorizer.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c4c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building naive bayes model\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de1a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9224608481490998\n",
      "severe_toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9900545838529557\n",
      "obscene\n",
      "\n",
      "Accuracy Score\n",
      " 0.9539139317294496\n",
      "threat\n",
      "\n",
      "Accuracy Score\n",
      " 0.9969982014275777\n",
      "insult\n",
      "\n",
      "Accuracy Score\n",
      " 0.9543964755500686\n",
      "identity_hate\n",
      "\n",
      "Accuracy Score\n",
      " 0.9912139423830144\n"
     ]
    }
   ],
   "source": [
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    train_target = train[clas]\n",
    "    model.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = model.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20aa57",
   "metadata": {},
   "source": [
    "## SGDClassifer\n",
    "Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the computational burden, achieving faster iterations in trade for a lower convergence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2ea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building SGD Classifiers\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model1 = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585dc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9553490295855763\n",
      "severe_toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9900044494300343\n",
      "obscene\n",
      "\n",
      "Accuracy Score\n",
      " 0.9790563448245608\n",
      "threat\n",
      "\n",
      "Accuracy Score\n",
      " 0.9970044682304429\n",
      "insult\n",
      "\n",
      "Accuracy Score\n",
      " 0.9720061916012308\n",
      "identity_hate\n",
      "\n",
      "Accuracy Score\n",
      " 0.9916651521893076\n"
     ]
    }
   ],
   "source": [
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    train_target = train[clas]\n",
    "    model1.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = model1.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dad4621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9730464808768511\n",
      "severe_toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9927618426907144\n",
      "obscene\n",
      "\n",
      "Accuracy Score\n",
      " 0.9850599419694055\n",
      "threat\n",
      "\n",
      "Accuracy Score\n",
      " 0.997693816545613\n",
      "insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9804162410463054\n",
      "identity_hate\n",
      "\n",
      "Accuracy Score\n",
      " 0.9937582643462785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "model5 = LR()\n",
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    train_target = train[clas]\n",
    "    model5.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = model5.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b613d",
   "metadata": {},
   "source": [
    "## RandomForestClassifer\n",
    "In this, we use forest of decision trees to classify what we want. Basically, we use majority rule principle for the classification of the classes we have in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b175e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "model3 = rfc(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f5a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9997493278853927\n",
      "severe_toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9999059979570223\n",
      "obscene\n",
      "\n",
      "Accuracy Score\n",
      " 0.9998495967312356\n",
      "threat\n",
      "\n",
      "Accuracy Score\n",
      " 0.9999373319713482\n",
      "insult\n",
      "\n",
      "Accuracy Score\n",
      " 0.9997618614911231\n",
      "identity_hate\n",
      "\n",
      "Accuracy Score\n",
      " 0.9998997311541571\n"
     ]
    }
   ],
   "source": [
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    train_target = train[clas]\n",
    "    model3.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = model3.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ac2ce",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "The Perceptron is a linear machine learning algorithm and may be considered one of the first and one of the simplest types of artificial neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf69520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9979820894774113\n",
      "severe_toxic\n",
      "\n",
      "Accuracy Score\n",
      " 0.9988406414699412\n",
      "obscene\n",
      "\n",
      "Accuracy Score\n",
      " 0.9986338369753902\n",
      "threat\n",
      "\n",
      "Accuracy Score\n",
      " 0.9998057291111794\n",
      "insult\n",
      "\n",
      "Accuracy Score\n",
      " 0.998145026351906\n",
      "identity_hate\n",
      "\n",
      "Accuracy Score\n",
      " 0.9994422545449988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "percetron = Perceptron()\n",
    "\n",
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    train_target = train[clas]\n",
    "    percetron.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = percetron.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee097e15",
   "metadata": {},
   "source": [
    "## MLPClassifier\n",
    "Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function by training on a dataset, where  is the number of dimensions for input and  is the number of dimensions for output. Given a set of features and a target y, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. \n",
    "#### The advantages of Multi-layer Perceptron are:\n",
    "<ul>\n",
    "    <li>Capability to learn non-linear models.</li>\n",
    "<li> Capability to learn models in real-time (on-line learning) using partial_fit.</li>\n",
    "</ul>\n",
    "\n",
    "#### The disadvantages of Multi-layer Perceptron (MLP) include:\n",
    "<ul>\n",
    "<li>MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.</li>\n",
    "\n",
    "<li>MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.</li>\n",
    "\n",
    "<li>MLP is sensitive to feature scaling.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b5e719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model2 = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dc8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9990161119501664\n",
      "severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9994547881507292\n",
      "obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9993983869249425\n",
      "threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9997681282939882\n",
      "insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9993169184876951\n",
      "identity_hate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score\n",
      " 0.9996678594481453\n"
     ]
    }
   ],
   "source": [
    "for clas in class_names:\n",
    "\n",
    "    print(clas)\n",
    "    #cross_validation(model2,train[clas])\n",
    "    train_target = train[clas]\n",
    "    model2.fit(train_matrix,train_target)\n",
    "\n",
    "    predictions = model2.predict(train_matrix)\n",
    "    print('\\nAccuracy Score\\n',accuracy_score(y[clas], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f062a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
